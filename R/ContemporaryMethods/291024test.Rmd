---
title: "291024test"
author: "Yakovlev D.M."
date: "2024-10-29"
output: html_document
---
### Полагаем уровень значимости alpha = 0.05 во всех упражениях, если не оговаривается обратное

## Часть 1
### Упражнение 1: Исследование предпочтений в музыке и возраста

Вы проводите исследование среди жителей города, чтобы выяснить, существует ли связь между предпочтениями в музыке и возрастом. Для этого были опрошены 100 человек, и им задали два вопроса:

Какую музыку вы предпочитаете?

Рок
Поп
Классика
Джаз
Какой у вас возраст?

Исходя из ответов, вы получили следующие данные в виде векторов:
```{r}
# Вектор предпочтений в музыке (категориальная переменная)
music_preference <- c("Рок", "Поп", "Поп", "Классика", "Рок", "Рок", "Джаз", "Поп", "Классика", "Поп",
                      "Джаз", "Поп", "Рок", "Классика", "Классика", "Поп", "Рок", "Классика", "Джаз", "Джаз",
                      "Поп", "Рок", "Классика", "Поп", "Классика", "Рок", "Поп", "Джаз", "Рок",
                      "Классика", "Классика", "Поп", "Джаз", "Рок", "Поп", "Классика", "Джаз", "Джаз", "Поп",
                      "Классика", "Рок", "Рок", "Поп", "Поп", "Классика", "Рок", "Джаз", "Джаз", "Классика",
                      "Поп", "Рок", "Поп", "Классика", "Джаз", "Джаз", "Поп", "Поп", "Рок", "Рок", "Поп", "Поп",
                      "Классика", "Рок", "Джаз", "Джаз", "Рок", "Поп", "Классика", "Поп", "Джаз", "Поп", "Джаз",
                      "Поп", "Поп", "Рок", "Рок", "Поп", "Поп", "Классика", "Рок", "Джаз", "Джаз", "Классика",
                      "Поп", "Рок", "Поп", "Классика", "Джаз", "Джаз", "Поп", "Поп", "Рок", "Рок", "Поп", "Поп",
                      "Классика", "Рок", "Джаз", "Рок", "Джаз")

# Вектор возраста (категориальная переменная)
age <- c("Молодой", "Средний", "Молодой", "Пожилой", "Молодой", "Средний", "Молодой", "Средний", "Пожилой", "Пожилой",
         "Молодой", "Молодой", "Средний", "Средний", "Пожилой", "Молодой", "Средний", "Пожилой", "Молодой", "Пожилой",
         "Молодой", "Средний", "Средний", "Пожилой", "Молодой", "Средний", "Пожилой", "Молодой", "Пожилой", "Молодой",
         "Средний", "Пожилой", "Средний", "Молодой", "Пожилой", "Молодой", "Молодой", "Средний", "Средний", "Пожилой",
         "Молодой", "Пожилой", "Средний", "Молодой", "Пожилой", "Средний", "Молодой", "Пожилой", "Молодой", "Средний",
         "Средний", "Пожилой", "Молодой", "Пожилой", "Молодой", "Средний", "Пожилой", "Молодой", "Пожилой", "Молодой",
         "Средний", "Пожилой", "Молодой", "Пожилой", "Молодой", "Средний", "Средний", "Пожилой", "Молодой", "Пожилой",
         "Молодой", "Средний", "Пожилой", "Молодой", "Пожилой", "Молодой", "Средний", "Пожилой", "Средний", "Молодой",
         "Пожилой", "Молодой", "Средний", "Молодой", "Пожилой", "Средний", "Молодой", "Пожилой", "Молодой", "Средний",
         "Средний", "Пожилой", "Молодой", "Пожилой", "Средний", "Молодой", "Пожилой", "Средний", "Молодой", "Молодой")

factor(age)
factor(music_preference)
chitable<-table(age, music_preference)
# Так как работаем с номинальными данными, построим таблицу сопряжённости.
# Полагаем, что если связи между предпочтениями в музыке и возрастом отсутствуют,
# то распределение должно быть равномерным.
# Тогда поставим:
# H0: Нет связи между музыкой и возрастом
# H1: Есть связь между музыкой и возрастом

# Воспользуемся критерием хи-квадрат (правосторонний). 
chisq.test(chitable)

# df = 6,
# X-squared = 4.1717
# p-value = 0.6535

# Так как p-value > 0.05 - не отвергаем гипотезу H0 (нет связи)
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### Упражнение 2:

Вы проводите исследование времени, затраченного студентами на выполнение домашних заданий по статистике. У вас есть данные о времени, которое потребовалось 100 студентам, чтобы выполнить задание, и вы хотите найти значение, которое разделяет 30% "самых быстрых" студентов (f = 0.3).

```{r}
# Данные времени выполнения задания (в минутах):
times <-  c(230, 95, 320, 305, 410, 510, 120, 355, 385, 490, 420, 85, 140, 
185, 125, 225, 430, 70, 100, 45, 90, 465, 240, 40, 105, 370, 
400, 130, 115, 485, 135, 265, 150, 280, 260, 425, 500, 200, 540, 
15, 345, 330, 495, 505, 145, 460, 350, 170, 65, 395, 295, 60, 
475, 205, 210, 235, 535, 360, 365, 50, 450, 555, 270, 290, 550, 
175, 255, 480, 285, 390, 25, 380, 275, 220, 300, 75, 545, 325, 
55, 470, 35, 80, 375, 110, 445, 315, 190, 215, 415, 560, 195, 
30, 165, 20, 520, 455, 405, 180, 515, 310)

# Нужно найти 0.3-квантиль 
f<-0.3
qnt<-quantile(times, f)
qnt
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### Упражнение 3:

Вы работаете в компании, занимающейся производством компонентов для автомобилей. У вас появилась новая машина, предназначенная для создания компонентов, и вы хотите убедиться, что средняя производительность этой машины соответствует вашим ожиданиям.

Для этой цели вы проводите серию измерений производительности новой машины, собирая данные о производительности на протяжении нескольких дней. Вы хотите проверить гипотезу о том, что среднее значение производительности машины равно конкретному значению m (например, m = 200 компонентов в час).

```{r}
# Вы собрали данные о производительности новой машины на протяжении 10 дней, и вот эти данные:
machine_performance <- c(198, 201, 203, 199, 202, 200, 197, 205, 199, 201)

# Матожидание (генеральное среднее значение)
m<-200

# Поскольку задача проверить, чему равно среднее значение m и мы не знаем ничего про
# трудоёмкость производства новой машины, рассматриваем двусторонний z-критерий

# H0: mu = m (средняя производительность соответствует ожиданиям)
# H1: mu != m (средняя производительность не соответствует ожиданиям)
t.test(machine_performance, mu = m, alternative="two.sided")

# df = 9
# t = 0.65465
# p-value = 0.5291

# Комментарий: не знаю, используется ли в t.test распределение Стьюдента (точный для произв. распр.) или
# нормальное распределение (точный для нормальных)

# p-value > 0.05 - не отвергаем H0 (ср. произв. соответствует ожиданиям)
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++


### Упражнение 4: Определение доверительного интервала для среднего времени доставки

Вы управляете интернет-магазином, и вам важно знать среднее время доставки товаров клиентам. 
Вы случайным образом выбрали 50 заказов и замерили время доставки (в днях) для этих заказов.

```{r}
# Ваши данные о времени доставки:

delivery_times <- c(3, 4, 2, 5, 3, 4, 3, 2, 4, 3, 5, 6, 4, 3, 2, 5, 6, 4, 3, 2, 5, 4, 3, 2, 4, 3, 5, 6, 4, 3, 2, 5, 4, 3, 2, 4, 3, 5, 6, 4, 3, 2, 5, 4, 3, 2, 4, 3, 5, 6)

mean_dt<-mean(delivery_times)
mean_dt
# Определить 95% доверительный интервал для среднего времени доставки в вашем интернет-магазине.
res<-t.test(delivery_times)

# 95% доверительный интервал через t.test 
res$conf.int
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### Упражнение 5: Определение доверительного интервала для медианы возраста сотрудников компании

Вы являетесь руководителем компании и хотите определить медианный возраст сотрудников, чтобы лучше понимать структуру возрастных групп в вашей команде. Вы случайным образом выбрали 30 сотрудников и замерили их возраст (в годах).
```{r}
# Ваши данные о возрасте сотрудников:
employee_age <- c(28, 32, 45, 36, 41, 29, 34, 37, 33, 38, 42, 31, 30, 35, 40, 39, 43, 27, 33, 44, 30, 38, 35, 31, 40, 29, 36, 39, 43, 30)

# Ваша задача: Определить 95% доверительный интервал для медианы возраста сотрудников в вашей компании.
# Используя критерий Вилкоксона, можем определить 95% доверительный интервал для медианы возраста
res<-wilcox.test(employee_age, conf.int=0.95)

res$conf.int
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### Упражнение 6: Оценка процента дефектных изделий на производстве

Вы работаете на производственной линии компании, которая производит электронные компоненты. Ваша задача - оценить процент дефектных изделий, производимых на линии. Вы верите, что истинный процент дефектных изделий составляет 5% (p = 0.05), но вы хотите это проверить на основе выборки.

Для этой задачи вы случайным образом выбрали 100 изделий с производственной линии и проверили каждое из них на наличие дефектов. В результате, вы получили данные:

```{r}
# 94 изделий были без дефектов (успех)
# 6 изделий были дефектными (неудача)
# Ваша задача: Проверить гипотезу о том, что процент дефектных изделий действительно равен 5% (p = 0.05) на основе данных выборки.

# Задача о доле признаков

n<-100
fail<-6
p_est<-fail/n

p_hyp<-0.05
# H0: p = 0.05 (Доля деф.изделий соответствует ожиданиям)
# H1: p != 0.05 (Доля деф.изделий не соответствует ожиданиям)
res<-prop.test(fail, n, p_hyp)

# p-value = 0.8185

# p-value > 0.05 - не отвергаем H0 (доля деф.изделий соответствует ожиданиям)
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
### Упражнение 7: Оценка нормальности распределения результатов испытаний

Вы работаете в лаборатории, где проводятся испытания материалов на прочность. Вашей задачей является определение, насколько результаты этих испытаний соответствуют нормальному распределению. Вы собрали данные о прочности материалов и хотите провести статистический тест, чтобы определить, является ли распределение результатов нормальным.

Здесь alpha = 0.10, чтобы уменьшить ошибку второго рода и, тем самым, увеличить мощность критерия и точнее разделять H0 и H1.
```{r}
# Для этой задачи, давайте предположим, что у вас есть выборка из 100 результатов испытаний на прочность материалов. Вы представили данные в виде вектора в R:

strength_data <- c(82.5, 78.9, 85.2, 88.1, 91.6, 87.5, 89.3, 80.7, 84.6, 86.8, 
                   81.2, 83.7, 90.5, 85.9, 92.3, 87.2, 84.6, 86.8, 89.4, 91.0, 
                   79.3, 85.7, 88.2, 83.6, 82.1, 84.8, 86.2, 87.9, 85.3, 81.7, 
                   88.9, 84.5, 85.8, 90.7, 86.1, 83.4, 88.7, 84.8, 87.2, 89.1, 
                   91.4, 82.7, 85.3, 87.8, 80.4, 83.9, 88.5, 90.2, 85.7, 86.9, 
                   89.6, 82.3, 86.8, 83.6, 87.4, 84.5, 88.0, 90.1, 85.6, 86.3, 
                   89.0, 83.1, 87.2, 85.8, 88.3, 84.9, 89.5, 86.7, 83.2, 88.8, 
                   85.1, 89.3, 87.1, 84.2, 86.0, 88.2, 85.5, 86.8, 83.8, 88.4, 
                   85.0, 89.1, 87.3, 84.0, 86.5, 88.6, 85.4, 87.0, 89.2, 86.6, 
                   84.3, 88.1, 85.9, 89.4, 86.4, 84.4, 88.3, 85.2, 89.5, 86.3)

# Для проверки распределения на соответствие нормальному распределению воспользуемся
# критерием Шапиро-Уилка (Shapiro-Wilk normality test)

# H0: Результаты соответствуют норм.распределению
# H1: Результаты не соответствуют норм.распределению
library(ggpubr)
result<-list(qqplot=ggqqplot(strength_data), shapiro_wilk=shapiro.test(strength_data))
result$qqplot
result$shapiro_wilk
result$shapiro_wilk$p.value
# p-value > 0.10 - не отвергаем H0 (результаты соответствуют нормальному распределению)
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### Упражнение 8: Анализ изменения цен на акции

Вы являетесь аналитиком в инвестиционной компании и отслеживаете изменение цен на акции некоторой компании. Вашей задачей является определение, можно ли считать изменение цен на акции случайным процессом.

Для анализа, вы собрали ежедневные данные о движении цен акций компании в течение года. Ваши данные представляют собой последовательность двоичных значений, где 1 обозначает повышение цен, а 0 - понижение цен.
```{r}
# Данные о движении цен на акции за исследуемый период:
price_movement <- c(1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1)
price_movement<-factor(price_movement)
# Проверка на случайность изменения цен
library(tseries)

# В интересах инвестиционной компании следить за понижением акций других компаний, чтобы иметь возможность приобрести большую долю компании за меньшие средства, поэтому имеет смысл рассматривать левосторонний критерий (понижение цен) 
# H0: Изменения цен случайны
# H1: Понижение цен не случайно
result<-runs.test(price_movement, alternative="less")

result$p.value
# p-value > 0.05 - не отвергаем H0 (изменения цен случайны)
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### Упражнение 9: Анализ изменения цен на акции


Сравнение эффективности двух портфелей инвестиций

Вы работаете в инвестиционной фирме и хотите определить, есть ли статистически значимая разница в средней доходности двух инвестиционных портфелей: портфеля A и портфеля B.

Для этой задачи вы собрали данные о доходности обоих портфелей за последние 24 месяца. Ваши данные представляют собой парные наблюдения, где каждая пара представляет собой доходность портфеля A и доходность портфеля B за один и тот же месяц.
```{r}
# Данные о доходности портфелей за два года (24 месяца):
portfolio_A <- c(0.02, 0.03, 0.01, 0.04, 0.02, 0.03, 0.05, 0.02, 0.01, 0.03, 0.04, 0.02, 0.03, 0.01, 0.04, 0.02, 0.03, 0.05, 0.02, 0.01, 0.03, 0.04, 0.02, 0.03)
portfolio_B <- c(0.03, 0.02, 0.04, 0.01, 0.03, 0.02, 0.01, 0.03, 0.04, 0.02, 0.03, 0.05, 0.02, 0.01, 0.03, 0.04, 0.02, 0.03, 0.01, 0.04, 0.02, 0.03, 0.05, 0.02)

# Воспользуемся t-критерием
# H0: Средние доходности отличаются
# H1: Средние доходности не отличаются
result<-t.test(portfolio_A, portfolio_B, paired=FALSE, alternative="two.sided")

result$p.value
# Так как p-value = 1, то отличий в средних доходностях между портфелями A и B нет. Не отвергаем H0.
```

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### Упражнение 10: Сравнение распределений доходности двух инвестиционных фондов

Вы управляете инвестиционной компанией и у вас есть два инвестиционных фонда, Фонд A и Фонд B, в которые клиенты вкладывают свои средства. Вы хотите определить, существует ли статистически значимая разница в распределениях доходности этих двух фондов.
```{r}
# Для этой задачи вы собрали данные о доходности фондов за последние 36 месяцев:
fund_A_returns <- c(0.02, 0.03, 0.01, 0.04, 0.02, 0.03, 0.05, 0.02, 0.01, 0.03, 0.04, 0.02, 0.03, 0.01, 0.04, 0.02, 0.03, 0.05, 0.02, 0.01, 0.03, 0.04, 0.02, 0.03, 0.01, 0.04, 0.02, 0.03, 0.05, 0.02, 0.01, 0.03, 0.04, 0.02, 0.03)
fund_B_returns <- c(0.03, 0.02, 0.04, 0.01, 0.03, 0.02, 0.01, 0.03, 0.04, 0.02, 0.03, 0.05, 0.02, 0.01, 0.03, 0.04, 0.02, 0.03, 0.01, 0.04, 0.02, 0.03, 0.05, 0.02, 0.03, 0.01, 0.04, 0.02, 0.03, 0.05, 0.01, 0.04, 0.02, 0.03, 0.02)

# Для проверки однородности воспользуемся критерием Колмогорова-Смирнова. 
# H0: Распределения совпадают
# H1: Распределения отличаются
result<-ks.test(fund_A_returns, fund_B_returns)

result$p.value
# p-value = 1. Не отвергаем H0
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### Упражнение 11: Оценка корреляции между рекламными расходами и продажами

Вы работаете в маркетинговом отделе компании, и вам нужно определить, существует ли статистически значимая корреляция между объемом рекламных расходов и объемом продаж продукта. 
```{r}
# Вы собрали данные о рекламных расходах и продажах в разные месяцы за последний год:
advertising_expenses <- c(10, 12, 15, 14, 18, 20, 22, 25, 27, 30, 32, 35)
sales_volume <- c(100, 110, 120, 115, 130, 140, 150, 145, 160, 165, 170, 175)
# Воспользуемся корреляционным критерием
# H0: Объёмы некоррелированы (rho = 0)
# H1: Объёмы коррелированы   (rho != 0)
result<-cor.test(advertising_expenses, sales_volume)
result$p.value
# p-value < 0.05. Отвергаем H0.
```
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### Упражнение 12: Сравнение распределений дефектов на двух производственных линиях

Вы работаете на производственной фабрике, где производятся детали для автомобилей. У вас есть две производственные линии: Линия A и Линия B, которые производят один и тот же тип деталей. Вам интересно, принадлежат ли распределения числа дефектных деталей на обеих линиях одному закону распределения.

```{r}
# Вы собрали данные о числе дефектных деталей, которые были произведены на обеих линиях за последний месяц
defects_line_A <- c(3, 5, 4, 6, 2, 3, 4, 5, 4, 3, 2, 6, 5, 4, 3, 2, 3, 4, 5, 6, 4, 3, 2, 5, 4, 3, 6)
defects_line_B <- c(4, 3, 6, 2, 3, 4, 5, 4, 3, 2, 6, 5, 4, 3, 2, 3, 5, 4, 6, 3, 2, 4, 5, 6, 3, 4, 2)

# H0: Производство линий A и B принадлежат одному закону распределения
# H1: -||- не принадлежат одному закону распределения.
result<-wilcox.test(defects_line_A, defects_line_B)
result$p.value
# p-value > 0.05 - не отвергаем H0
```

```{r}

```

## Часть 2
Скачайте набор данных из открытого источника.
Проведите визуальный анализ выбранных данных, используя как можно больше методов, рассмотренных на втором занятии.

Диетический датасет.
1. ID
2. Возраст
3. Пол
4. Исходный вес участника (в фунтах)
5. BMR - количество энергии (в калориях) для нормальной жизнедеятельности человека в течение дня. 6. Дневное потребление калорий.
7. Дефицит или профицит дневных калорий
8. Изменение веса (в фунтах).
9. Длительность наблюдений
10. Уровень физической активности
11. Качество сна
12. Уровень стресса
13. Итоговый вес (в фунтах)
About this file

Add Suggestion
1. Participant ID: Unique identifier for each participant in the study.

2. Age: The age of the participant (in years), which can influence metabolism and weight change.

3. Gender: Gender of the participant (M/F), as physiological differences may affect weight management.

4. Current Weight (lbs): The participant's weight at the beginning of the study, serving as a baseline for weight change.

5. BMR (Calories): Basal Metabolic Rate, calculated using the Mifflin-St Jeor equation, representing the number of calories burned at rest.

6. Daily Calories Consumed: Total caloric intake per day, including variability to reflect real-world eating habits.

7. Daily Caloric Surplus/Deficit: The difference between calories consumed and BMR, indicating whether the participant is in a caloric surplus or deficit.

8. Weight Change (lbs): The estimated change in weight over a specified duration, based on caloric surplus/deficit.

9. Duration (weeks): The time period over which weight change is measured, ranging from 1 to 12 weeks.

10. Physical Activity Level: Self-reported level of physical activity, categorized as Sedentary, Lightly Active, Moderately Active, or Very Active.

11. Macronutrient Breakdown: Composition of the participant's diet, expressed as percentages of carbohydrates, proteins, and fats.

12. Sleep Quality: Self-reported quality of sleep, categorized as Poor, Fair, Good, or Excellent, which can affect weight management.

13. Stress Level: A numerical score (1-10) indicating the participant's perceived stress level, as stress can influence eating behaviors and weight.
```{r}
library(tidyverse)
library(ggplot2)
library(patchwork)
library(GGally)
df<-read.csv("weight_change_dataset.csv")
df
```
```{r}
names(df)
```
Можно делать отдельный анализ каждого количественного признака, например, Age.
* Normal Probability Plot (для проверки на нормальность)
* Boxplot с каждым качественным признаком, а также с учётом пола (Gender)
* Гистограммы со средними значениями и доверительным интервалом
Аналогично можно применить и для остальных признаков

Age
```{r}
ageplot<-ggplot(df)+aes(y=Age)
```

```{r}
ggplot(df)+aes(sample=Age)+stat_qq()+stat_qq_line()
ggplot(df)+aes(sample=Age, color=Gender)+stat_qq()+stat_qq_line()
```
Гистограммы
```{r}
ageplot+aes(x=as.factor(Stress.Level))+geom_boxplot()+labs(x="Stress level")
ageplot+aes(x=as.factor(Stress.Level), color = Gender)+geom_boxplot()+labs(x="Stress level")+facet_wrap(~Gender)
ageplot+aes(x=as.factor(Sleep.Quality))+geom_boxplot()+labs(x = "Sleep quality")
ageplot+aes(x=as.factor(Sleep.Quality), color = Gender)+geom_boxplot()+labs(x = "Sleep quality")+facet_wrap(~Gender)
ageplot+aes(x=as.factor(Physical.Activity.Level))+geom_boxplot()+labs(x = "Physical.Activity.Level")
ageplot+aes(x=as.factor(Physical.Activity.Level), color = Gender)+geom_boxplot()+labs(x = "Physical.Activity.Level")+facet_wrap(~Gender)

```

```{r}
ggplot(df)+aes(x=Age)+geom_histogram()
ggplot(df)+aes(x=Age)+geom_histogram(binwidth = 5)+facet_wrap(~Gender)
```

На этом графике можно заметить, что мужчины потребляют больше энергии на содержание себя, чем женщины.
```{r}
age_vs_calories<-ggplot(df, aes(Age, BMR..Calories., color=Gender))+geom_point()+labs(title="Diet: Age vs Calories", x = "Age", y = "Calories")
age_vs_calories
```
В разделении (через facet_wrap())
```{r}
ggplot(df, aes(Age, BMR..Calories., color=Gender))+geom_point()+labs(title="Diet: Age vs Calories", x = "Age", y = "Calories")+facet_wrap(~Gender)
```
Используем ggpairs, чтобы посмотреть на количественные признаки попарно.
Замечаем сильную положительную корреляцию у 
* BMR(Calories) vs. Current_Weight
* Final_Weight vs. Current_Weight
* BMR(Calories) vs. Final_Weight

Можно предположить, что формула BMR зависит от веса и использует Current_Weight и Final_Weight, что имеет смысл, так как с изменением веса меняется число затрачиваемой энергии на нормальную жизнедеятельность.
```{r}
names(df)
num_cols<-c("Age", "Current.Weight..lbs.", "BMR..Calories.", "Daily.Calories.Consumed", "Daily.Caloric.Surplus.Deficit", "Weight.Change..lbs.", "Duration..weeks.", "Final.Weight..lbs.")
qual_cols<-c("Participant.ID", "Gender", "Physical.Activity.Level", "Sleep.Quality", "Stress.Level")
# gpair<-ggpairs(df[-c(1, 3, 10, 11, 12)])
# gpair
```
```{r}
ggpairs(df[c(num_cols, "Gender")], aes(color = Gender, alpha = 0.5),
        diag = list(continuous = wrap("barDiag")))
```

```{r}
ggpairs(df[c(num_cols, "Sleep.Quality")], aes(color = Sleep.Quality, alpha = 0.5),
        diag = list(continuous = wrap("barDiag", bins=20)))
```

```{r}
ggpairs(df[c(num_cols, "Physical.Activity.Level")], aes(color = Physical.Activity.Level, alpha = 0.5),
        diag = list(continuous = wrap("barDiag")))
```
```{r}
gcal<-ggplot(df, aes(BMR..Calories., Daily.Calories.Consumed, color=Gender, shape=Gender)) + geom_point()
gcal + geom_smooth(method="lm", formula=y~x, se=TRUE)
```
По графику можно заметить потолок в "4000" по потребляемым калориям, что делает анализ менее точным.

Теперь посмотрим на другие графики с учётом пола и других качественных признаков
При плохом качестве сна вес как у мужчин, так и у женщин чаще уменьшается.
```{r}
gage<-ggplot(df, aes(Daily.Caloric.Surplus.Deficit, Weight.Change..lbs., color=Gender, shape=Sleep.Quality))+geom_point()+facet_wrap(~Sleep.Quality + Gender)
gage
```
Проверим соответствие данных нормальному распределению через qqplot().
Начальный вес имеет довольно схожее в плане нормальности распределение
```{r}
dfplot<-ggplot(df)
dfplot+aes(sample=Daily.Calories.Consumed)+stat_qq()+stat_qq_line()
dfplot+aes(sample=Current.Weight..lbs.)+stat_qq()+stat_qq_line()
```

```{r}
ggplot(df, aes(Gender, Weight.Change..lbs.))+geom_bar(fun="mean", stat="summary", fill = "grey")+stat_summary(fun.data=mean_se, geom="errorbar")
```

Хочется сравнить дневное потребление калорий с итоговым весом и уровнем стресса. Предполагаем, что они коррелируют положительно. Посмотрим на графики
```{r}
g1<-ggplot(df)+aes(x=as.factor(Stress.Level), y = Daily.Calories.Consumed)+geom_boxplot()+labs(x="Stress level", y = "Daily Calories Consumed")
g2<-ggplot(df)+aes(x=as.factor(Sleep.Quality), y = Daily.Calories.Consumed)+geom_boxplot()+labs(x="Sleep quality", y = "Daily Calories Consumed")
g1
g2
```


## Часть 3

Используя набор данных "housing" (содержащий статистические данные по недвижимости в Калифорнии) постройте модель прогноза цен на жилье. При построении и исследовании модели используйте как можно больше методов, рассмотренных на третьем занятии. Сделайте выводы.
```{r}
housing<-read.csv("housing.csv")
head(housing)
summary(housing)
nms<-names(housing)
unique(housing$ocean_proximity)
```
Пустующие значения total_bedrooms можно попробовать заменить на среднее
```{r}
houseplot<-ggplot(housing)
```

Можно получить силуэт Калифорнии, если рассмотреть график по longitude, latitude
```{r}
houseplot+aes(longitude, latitude, color=ocean_proximity)+geom_point()
```

Хотим построить модель прогноза цен на жильё. Для этого построим регрессионные модели. Особый интерес представляет цен на жильё по признаку "ocean_proximity". Будем рассматривать их отдельно.
Так как прогнозируем цены на жильё (median_house_value), 
```{r}
nms
```

```{r}
library(car)
library(tidyverse)
```

```{r}
houseplot+aes(sample=log(median_house_value))+stat_qq()+stat_qq_line()
houseplot+aes(sample=log(median_income))+stat_qq()+stat_qq_line()
houseplot+aes(sample=total_rooms)+stat_qq()+stat_qq_line()
houseplot+aes(sample=total_bedrooms)+stat_qq(na.rm=TRUE)+stat_qq_line()
houseplot+aes(sample=log(population))+stat_qq()+stat_qq_line()
```
Можно увидеть, что median_house_value и median_income имеют близкое к lognorm распределению. total_rooms и total_bedrooms зависимы, так как число комнат зависит  от числа спален.

```{r}
total_rooms<-housing$total_rooms
total_bedrooms<-housing$total_bedrooms
m_beddoor<-lm(total_rooms~total_bedrooms)
bc<-boxCox(m_beddoor)
lambda<-bc$x[which.max(bc$y)]
total_rooms<-total_rooms^lambda
m_n<-lm(total_rooms~total_bedrooms)
summary(m_beddoor)
summary(m_n)
```
Получили R-squared = 0.8656, что подразумевает сильную зависимость total_rooms от total_bedrooms.

Построим гистограммы для количественных признаков.
```{r}
num_attr<-housing[,1:9]
lapply(num_attr, function(x){ggplot(num_attr)+aes(x=x)+geom_histogram()+labs(title=names(x)[1])})
```

```{r}
set<-list()
for(name in unique(housing$ocean_proximity)){
  set<-append(set, list(housing|>filter(ocean_proximity==name)))  
}
names(set)<-unique(housing$ocean_proximity)
```

Можно предположить, что median_house_value как-то зависит от median_income, population, housing_median_age
```{r}
library(lmtest)
library(car)
m_1H<-lm(median_house_value ~ median_income*population*housing_median_age, set$`NEAR BAY`)
summary(m_1H)
bx<-boxCox(m_1H)
lambda<-bx$x[which.max(bx$y)]
set_temp<-set[[1]]
set_temp["median_house_value"]<-set_temp["median_house_value"]^lambda
m_2H<-lm(median_house_value~median_income*population*housing_median_age, set_temp)
summary(m_2H)
library(broom)
augm_1H<-augment(m_1H)
ggplot(augm_1H, aes(x=.fitted, y=.resid))+geom_point()
augm_2H<-augment(m_2H)
ggplot(augm_2H, aes(x=.fitted, y=.resid))+geom_point()
```

```{r}
lapply(set, function(housing){ggcorr(housing[,1:9])})
```
Можем заметить корреляцию с households, median_income и total_rooms

```{r}
library(generics)
m_NEARBAY<-lm(log(median_house_value)~log(population) + (log(households) + log(total_rooms))*log(median_income),set$`NEAR BAY`)
outlierTest(m_NEARBAY)
augm_NEARBAY<-augment(m_NEARBAY)
ggplot(augm_NEARBAY) + aes(x=.fitted, y=.resid)+geom_point()
summary(m_NEARBAY)
```
```{r}
m_1HOCEAN<-lm(median_house_value~median_income*population*total_rooms, set$`<1H OCEAN`)
dwtest(m_1HOCEAN)
augm_1HOCEAN<-augment(m_1HOCEAN)
ggplot(augm_1HOCEAN) + aes(x=.fitted, y=.resid)+geom_point()
summary(m_1HOCEAN)
```

```{r}
m_INLAND<-lm(median_house_value~median_income*households+log(total_rooms)+population*households, set$INLAND)
augm_INLAND<-augment(m_INLAND)
ggplot(augm_INLAND) + aes(x=.fitted, y=.resid)+geom_point()
summary(m_INLAND)
```

```{r}
m_NEAROCEAN<-lm(log(median_house_value)~log(median_income)*households+population+households + total_rooms, set$`NEAR OCEAN`)
augm_NEAROCEAN<-augment(m_NEAROCEAN)
ggplot(augm_NEAROCEAN) + aes(x=.fitted, y=.resid)+geom_point()
summary(m_NEAROCEAN)
```
Вывод: median_house_value коррелирует с median_income, а также с population, households и total_rooms.
